{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<polars.config.Config at 0x148bc8250>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global configurations for sklearn:\n",
    "set_config(transform_output = \"pandas\")\n",
    "\n",
    "# Global configurations for pandas:\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Global configurations for polars:\n",
    "pl.Config.activate_decimals(True).set_tbl_hide_column_data_types(True)\n",
    "pl.Config(\n",
    "    **dict(tbl_formatting = 'ASCII_FULL_CONDENSED',\n",
    "            tbl_hide_column_data_types = False,\n",
    "            tbl_hide_dataframe_shape = True,\n",
    "            fmt_float = \"mixed\",\n",
    "            tbl_cell_alignment = 'CENTER',\n",
    "            tbl_hide_dtype_separator = True,\n",
    "            tbl_cols = 100,\n",
    "            tbl_rows = 50,\n",
    "            fmt_str_lengths = 100,\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameProcessor:\n",
    "    \"\"\" Dataframe processing class.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_types(df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\" Converts columns' data types for memory.\n",
    "\n",
    "        Argument:\n",
    "        df (polars dataframe): The DataFrame to be processed.\n",
    "        \"\"\"\n",
    "        for column in df.columns:\n",
    "            if column == \"target\":\n",
    "                df = df.with_columns(pl.col(column).cast(pl.Int8))\n",
    "            elif column in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(column).cast(pl.Int32))\n",
    "            elif column == \"date_decision\":\n",
    "                df = df.with_columns(pl.col(column).cast(pl.Date))\n",
    "            elif column[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(column).cast(pl.Float64))\n",
    "            elif column[-1] == \"M\":\n",
    "                df = df.with_columns(pl.col(column).cast(pl.String))\n",
    "            elif column[-1] == \"D\":\n",
    "                df = df.with_columns(pl.col(column).cast(pl.Date))            \n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def date_processor(df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\" Processes the date columns.\n",
    "\n",
    "        Argument:\n",
    "        df (polars dataframe): The DataFrame to be processed.\n",
    "        \"\"\"\n",
    "        for column in df.columns:\n",
    "            if column[-1] == \"D\":\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n",
    "                df = df.with_columns(pl.col(col).dt.total_days())\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float32))\n",
    "\n",
    "            if column == \"date_decision\":\n",
    "                df = df.with_columns(\n",
    "                    pl.col(column).dt.year().alias(\"year_decision\"),\n",
    "                    pl.col(column).dt.month().alias(\"month_decision\"),\n",
    "                    pl.col(column).dt.day().alias(\"day_decision\"),\n",
    "                    pl.col(column).dt.week().alias(\"week_decision\"),\n",
    "                    pl.col(column).dt.weekday().alias(\"weekday_decision\"),\n",
    "                    pl.col(column).dt.quarter().alias(\"quarter_decision\")\n",
    "                )\n",
    "\n",
    "        df = df.drop([\"date_decision\", \"WEEK_NUM\", \"MONTH\"])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def delete_nulls_column(df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\" Deletes columns with more than 80% of null values.\n",
    "\n",
    "        Argument:\n",
    "        df (polars dataframe): The DataFrame to be processed.\n",
    "        \"\"\"\n",
    "        for column in df.columns:\n",
    "            if column not in [\"case_id\", \"target\"]:\n",
    "                null_percentage = df[column].is_null().sum() / df.shape[0]\n",
    "\n",
    "                if null_percentage > 0.80:\n",
    "                    df = df.drop(column)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def drop_duplicates(df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\" Drops duplicates from the DataFrame.\n",
    "\n",
    "        Argument:\n",
    "        df (polars dataframe): The DataFrame to be processed.\n",
    "        \"\"\"\n",
    "        df = df.unique(keep=\"first\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def drop_columns_with_too_many_categories(df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\" Drops columns with more than 100 categories or just 1.\n",
    "\n",
    "        Argument:\n",
    "        df (polars dataframe): The DataFrame to be processed.\n",
    "        \"\"\"\n",
    "        for column in df.columns:\n",
    "            if (column not in [\"target\", \"case_id\"]) & (df[column].dtype == pl.String):\n",
    "                categories_count = df[column].n_unique()\n",
    "\n",
    "                if (categories_count == 1) | (categories_count > 200):\n",
    "                    df = df.drop(column)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregator:\n",
    "    \"\"\"Dataframe aggreagating class.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def max_agg(df: pl.DataFrame) -> pl.Expr:\n",
    "        \"\"\"Aggregates the DataFrame by the maximum value.\n",
    "\n",
    "        Argument:\n",
    "        df (polars dataframe): The DataFrame to be aggregated.\n",
    "        \"\"\"\n",
    "        columns = [column for column in df.columns if column[-1] in (\"P\", \"A\")]\n",
    "\n",
    "        expr_max = [pl.max(column).alias(f\"max_{column}\") for column in columns]\n",
    "\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def min_agg(df: pl.DataFrame) -> pl.Expr:\n",
    "        \"\"\"Aggregates the DataFrame by the minimum value.\n",
    "\n",
    "        Argument:\n",
    "        df (polars dataframe): The DataFrame to be aggregated.\n",
    "        \"\"\"\n",
    "        columns = [column for column in df.columns if column[-1] in (\"P\", \"A\")]\n",
    "\n",
    "        expr_min = [pl.min(column).alias(f\"min_{column}\") for column in columns]\n",
    "\n",
    "        return expr_min\n",
    "\n",
    "    @staticmethod\n",
    "    def date_agg(df: pl.DataFrame) -> pl.Expr:\n",
    "        \"\"\"Aggregates the DataFrame by the date columns.\n",
    "\n",
    "        Argument:\n",
    "        df (polars dataframe): The DataFrame to be aggregated.\n",
    "        \"\"\"\n",
    "        columns = [column for column in df.columns if column[-1] == \"D\"]\n",
    "\n",
    "        expr_date = [pl.max(column).alias(f\"max_{column}\") for column in columns]\n",
    "\n",
    "        return expr_date\n",
    "\n",
    "    @staticmethod\n",
    "    def string_agg(df: pl.DataFrame) -> pl.Expr:\n",
    "        \"\"\"Aggregates the DataFrame by the string columns.\n",
    "\n",
    "        Argument:\n",
    "        df (polars dataframe): The DataFrame to be aggregated.\n",
    "        \"\"\"\n",
    "        columns = [column for column in df.columns if column[-1] == \"M\"]\n",
    "\n",
    "        expr_string = [pl.max(column).alias(f\"max_{column}\") for column in columns]\n",
    "\n",
    "        return expr_string\n",
    "\n",
    "    @staticmethod\n",
    "    def others_agg(df: pl.DataFrame) -> pl.Expr:\n",
    "        \"\"\"Aggregates the DataFrame by the other columns.\n",
    "\n",
    "        Argument:\n",
    "        df (polars dataframe): The DataFrame to be aggregated.\n",
    "        \"\"\"\n",
    "        columns = [column for column in df.columns if column in (\"T\", \"L\")]\n",
    "\n",
    "        expr_others = [pl.max(column).alias(f\"max_{column}\") for column in columns]\n",
    "\n",
    "        return expr_others\n",
    "\n",
    "    @staticmethod\n",
    "    def count_agg(df: pl.DataFrame) -> pl.Expr:\n",
    "        \"\"\"Aggregates the DataFrame by the count of rows.\n",
    "\n",
    "        Argument:\n",
    "        df (polars dataframe): The DataFrame to be aggregated.\n",
    "        \"\"\"\n",
    "        columns = [column for column in df.columns if \"num_group\" in column]\n",
    "\n",
    "        expr_max = [pl.max(column).alias(f\"max_{column}\") for column in columns]\n",
    "\n",
    "        return expr_max\n",
    "\n",
    "    @staticmethod\n",
    "    def agg_expr(df: pl.DataFrame) -> pl.Expr:\n",
    "        expr_all = (\n",
    "            Aggregator.max_agg(df)\n",
    "            + Aggregator.min_agg(df)\n",
    "            + Aggregator.date_agg(df)\n",
    "            + Aggregator.string_agg(df)\n",
    "            + Aggregator.others_agg(df)\n",
    "            + Aggregator.count_agg(df)\n",
    "        )\n",
    "        return expr_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path: str, depth: int) -> pl.DataFrame:\n",
    "    df = pl.read_parquet(path)\n",
    "    df = df.pipe(DataFrameProcessor.convert_types)\n",
    "\n",
    "    if depth in (1, 2):\n",
    "        df = df.group_by('case_id').agg(Aggregator.agg_expr(df))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_files(paths: list, depth: int) -> pl.DataFrame:\n",
    "    dfs = [read_file(path, depth) for path in paths]\n",
    "    df = pl.concat(dfs)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.3 ms, sys: 71.3 ms, total: 126 ms\n",
      "Wall time: 150 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>date_decision</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK_NUM</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>201901</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id date_decision   MONTH  WEEK_NUM  target\n",
       "0        0    2019-01-03  201901         0       0\n",
       "1        1    2019-01-03  201901         0       0\n",
       "2        2    2019-01-04  201901         0       0\n",
       "3        3    2019-01-03  201901         0       0\n",
       "4        4    2019-01-04  201901         0       1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Test pandas reading time\n",
    "test_pandas_df = pd.read_parquet('data/train/train_base.parquet')\n",
    "test_pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>date_decision</th><th>MONTH</th><th>WEEK_NUM</th><th>target</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>&quot;2019-01-03&quot;</td><td>201901</td><td>0</td><td>0</td></tr><tr><td>1</td><td>&quot;2019-01-03&quot;</td><td>201901</td><td>0</td><td>0</td></tr><tr><td>2</td><td>&quot;2019-01-04&quot;</td><td>201901</td><td>0</td><td>0</td></tr><tr><td>3</td><td>&quot;2019-01-03&quot;</td><td>201901</td><td>0</td><td>0</td></tr><tr><td>4</td><td>&quot;2019-01-04&quot;</td><td>201901</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "+---------+---------------+--------+----------+--------+\n",
       "| case_id | date_decision |  MONTH | WEEK_NUM | target |\n",
       "|   i64   |      str      |   i64  |    i64   |   i64  |\n",
       "+======================================================+\n",
       "|    0    |   2019-01-03  | 201901 |     0    |    0   |\n",
       "|    1    |   2019-01-03  | 201901 |     0    |    0   |\n",
       "|    2    |   2019-01-04  | 201901 |     0    |    0   |\n",
       "|    3    |   2019-01-03  | 201901 |     0    |    0   |\n",
       "|    4    |   2019-01-04  | 201901 |     0    |    1   |\n",
       "+---------+---------------+--------+----------+--------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1526659, 5)\n",
      "CPU times: user 70.3 ms, sys: 27.4 ms, total: 97.7 ms\n",
      "Wall time: 41.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = pl.read_parquet('data/train/train_base.parquet')\n",
    "display(df_train.head())\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comment: Polars read data faster than pandas, since there are many files, it might be a good idea for me to mitigate to Polars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>target</th><th>year_decision</th><th>month_decision</th><th>day_decision</th><th>week_decision</th><th>weekday_decision</th><th>quarter_decision</th></tr><tr><td>i32</td><td>i8</td><td>i32</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>2019</td><td>1</td><td>3</td><td>1</td><td>4</td><td>1</td></tr><tr><td>1</td><td>0</td><td>2019</td><td>1</td><td>3</td><td>1</td><td>4</td><td>1</td></tr><tr><td>2</td><td>0</td><td>2019</td><td>1</td><td>4</td><td>1</td><td>5</td><td>1</td></tr><tr><td>3</td><td>0</td><td>2019</td><td>1</td><td>3</td><td>1</td><td>4</td><td>1</td></tr><tr><td>4</td><td>1</td><td>2019</td><td>1</td><td>4</td><td>1</td><td>5</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "+---------+--------+-------------+-------------+------------+------------+------------+------------+\n",
       "| case_id | target | year_decisi | month_decis | day_decisi | week_decis | weekday_de | quarter_de |\n",
       "|   i32   |   i8   |      on     |     ion     |     on     |     ion    |   cision   |   cision   |\n",
       "|         |        |     i32     |      i8     |     i8     |     i8     |     i8     |     i8     |\n",
       "+==================================================================================================+\n",
       "|    0    |    0   |     2019    |      1      |      3     |      1     |      4     |      1     |\n",
       "|    1    |    0   |     2019    |      1      |      3     |      1     |      4     |      1     |\n",
       "|    2    |    0   |     2019    |      1      |      4     |      1     |      5     |      1     |\n",
       "|    3    |    0   |     2019    |      1      |      3     |      1     |      4     |      1     |\n",
       "|    4    |    1   |     2019    |      1      |      4     |      1     |      5     |      1     |\n",
       "+---------+--------+-------------+-------------+------------+------------+------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1526659, 8)\n",
      "(1526659, 8)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.pipe(DataFrameProcessor.convert_types)\n",
    "df_train = df_train.pipe(DataFrameProcessor.date_processor)\n",
    "\n",
    "display(df_train.head())\n",
    "print(df_train.shape)\n",
    "df_train = df_train.pipe(DataFrameProcessor.delete_nulls_column)\n",
    "df_train = df_train.pipe(DataFrameProcessor.drop_duplicates)\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>last180dayaveragebalance_704A</th><th>last180dayturnover_1134A</th><th>last30dayturnover_651A</th><th>num_group1</th><th>openingdate_857D</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>225</td><td>null</td><td>null</td><td>null</td><td>0</td><td>&quot;2016-08-16&quot;</td></tr><tr><td>331</td><td>null</td><td>null</td><td>null</td><td>0</td><td>&quot;2015-03-19&quot;</td></tr><tr><td>358</td><td>null</td><td>null</td><td>null</td><td>0</td><td>&quot;2014-09-02&quot;</td></tr><tr><td>390</td><td>null</td><td>null</td><td>null</td><td>0</td><td>&quot;2014-07-23&quot;</td></tr><tr><td>390</td><td>null</td><td>null</td><td>null</td><td>1</td><td>&quot;2015-10-01&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "+---------+------------------+------------------+------------------+------------+------------------+\n",
       "| case_id | last180dayaverag | last180dayturnov | last30dayturnove | num_group1 | openingdate_857D |\n",
       "|   i64   |   ebalance_704A  |     er_1134A     |      r_651A      |     i64    |        str       |\n",
       "|         |        f64       |        f64       |        f64       |            |                  |\n",
       "+==================================================================================================+\n",
       "|   225   |       null       |       null       |       null       |      0     |    2016-08-16    |\n",
       "|   331   |       null       |       null       |       null       |      0     |    2015-03-19    |\n",
       "|   358   |       null       |       null       |       null       |      0     |    2014-09-02    |\n",
       "|   390   |       null       |       null       |       null       |      0     |    2014-07-23    |\n",
       "|   390   |       null       |       null       |       null       |      1     |    2015-10-01    |\n",
       "+---------+------------------+------------------+------------------+------------+------------------+"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_debit = pl.read_parquet('data/train/train_debitcard_1.parquet')\n",
    "train_debit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>addres_district_368M</th><th>addres_role_871L</th><th>addres_zip_823M</th><th>conts_role_79M</th><th>empls_economicalst_849M</th><th>empls_employedfrom_796D</th><th>empls_employer_name_740M</th><th>num_group1</th><th>num_group2</th><th>relatedpersons_role_762T</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>5</td><td>&quot;a55475b1&quot;</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>null</td><td>&quot;a55475b1&quot;</td><td>0</td><td>0</td><td>null</td></tr><tr><td>6</td><td>&quot;P55_110_32&quot;</td><td>&quot;CONTACT&quot;</td><td>&quot;P10_68_40&quot;</td><td>&quot;P38_92_157&quot;</td><td>&quot;P164_110_33&quot;</td><td>null</td><td>&quot;a55475b1&quot;</td><td>0</td><td>0</td><td>null</td></tr><tr><td>6</td><td>&quot;P55_110_32&quot;</td><td>&quot;PERMANENT&quot;</td><td>&quot;P10_68_40&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>null</td><td>&quot;a55475b1&quot;</td><td>0</td><td>1</td><td>null</td></tr><tr><td>6</td><td>&quot;P204_92_178&quot;</td><td>&quot;CONTACT&quot;</td><td>&quot;P65_136_169&quot;</td><td>&quot;P38_92_157&quot;</td><td>&quot;P164_110_33&quot;</td><td>null</td><td>&quot;a55475b1&quot;</td><td>1</td><td>0</td><td>&quot;OTHER_RELATIVE&quot;</td></tr><tr><td>6</td><td>&quot;P191_109_75&quot;</td><td>&quot;CONTACT&quot;</td><td>&quot;P10_68_40&quot;</td><td>&quot;P7_147_157&quot;</td><td>&quot;a55475b1&quot;</td><td>null</td><td>&quot;a55475b1&quot;</td><td>1</td><td>1</td><td>&quot;OTHER_RELATIVE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
       "| case_i | addres | addres | addres | conts_ | empls_ | empls_ | empls_ | num_gr | num_gr | relate |\n",
       "|    d   | _distr | _role_ | _zip_8 | role_7 | econom | employ | employ |  oup1  |  oup2  | dperso |\n",
       "|   i64  | ict_36 |  871L  |   23M  |   9M   | icalst | edfrom | er_nam |   i64  |   i64  | ns_rol |\n",
       "|        |   8M   |   str  |   str  |   str  |  _849M |  _796D | e_740M |        |        | e_762T |\n",
       "|        |   str  |        |        |        |   str  |   str  |   str  |        |        |   str  |\n",
       "+==================================================================================================+\n",
       "|    5   | a55475 |  null  | a55475 | a55475 | a55475 |  null  | a55475 |    0   |    0   |  null  |\n",
       "|        |   b1   |        |   b1   |   b1   |   b1   |        |   b1   |        |        |        |\n",
       "|    6   | P55_11 | CONTAC | P10_68 | P38_92 | P164_1 |  null  | a55475 |    0   |    0   |  null  |\n",
       "|        |  0_32  |    T   |   _40  |  _157  |  10_33 |        |   b1   |        |        |        |\n",
       "|    6   | P55_11 | PERMAN | P10_68 | a55475 | a55475 |  null  | a55475 |    0   |    1   |  null  |\n",
       "|        |  0_32  |   ENT  |   _40  |   b1   |   b1   |        |   b1   |        |        |        |\n",
       "|    6   | P204_9 | CONTAC | P65_13 | P38_92 | P164_1 |  null  | a55475 |    1   |    0   | OTHER_ |\n",
       "|        |  2_178 |    T   |  6_169 |  _157  |  10_33 |        |   b1   |        |        | RELATI |\n",
       "|        |        |        |        |        |        |        |        |        |        |   VE   |\n",
       "|    6   | P191_1 | CONTAC | P10_68 | P7_147 | a55475 |  null  | a55475 |    1   |    1   | OTHER_ |\n",
       "|        |  09_75 |    T   |   _40  |  _157  |   b1   |        |   b1   |        |        | RELATI |\n",
       "|        |        |        |        |        |        |        |        |        |        |   VE   |\n",
       "+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_person = pl.read_parquet('data/train/train_person_2.parquet')\n",
    "train_person.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>addres_district_368M</th></tr><tr><td>i64</td><td>str</td></tr></thead><tbody><tr><td>251566</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1930547</td><td>&quot;a55475b1&quot;</td></tr><tr><td>2586625</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1881392</td><td>&quot;a55475b1&quot;</td></tr><tr><td>2615871</td><td>&quot;a55475b1&quot;</td></tr><tr><td>2657955</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1774201</td><td>&quot;a55475b1&quot;</td></tr><tr><td>2670498</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1389479</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1466412</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1678359</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1850473</td><td>&quot;a55475b1&quot;</td></tr><tr><td>2659890</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1274931</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1751755</td><td>&quot;a55475b1&quot;</td></tr><tr><td>2672076</td><td>&quot;a55475b1&quot;</td></tr><tr><td>208196</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1744181</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1353677</td><td>&quot;a55475b1&quot;</td></tr><tr><td>905107</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1261411</td><td>&quot;a55475b1&quot;</td></tr><tr><td>2530664</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1334798</td><td>&quot;a55475b1&quot;</td></tr><tr><td>985068</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1613871</td><td>&quot;a55475b1&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>933668</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1640568</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1773081</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1845057</td><td>&quot;a55475b1&quot;</td></tr><tr><td>820382</td><td>&quot;a55475b1&quot;</td></tr><tr><td>35364</td><td>&quot;a55475b1&quot;</td></tr><tr><td>879791</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1360977</td><td>&quot;a55475b1&quot;</td></tr><tr><td>195950</td><td>&quot;a55475b1&quot;</td></tr><tr><td>827724</td><td>&quot;a55475b1&quot;</td></tr><tr><td>866557</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1131</td><td>&quot;a55475b1&quot;</td></tr><tr><td>823428</td><td>&quot;a55475b1&quot;</td></tr><tr><td>785691</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1490105</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1501347</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1517112</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1414220</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1723798</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1785035</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1692331</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1793282</td><td>&quot;a55475b1&quot;</td></tr><tr><td>1361355</td><td>&quot;a55475b1&quot;</td></tr><tr><td>598890</td><td>&quot;a55475b1&quot;</td></tr><tr><td>879377</td><td>&quot;a55475b1&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "+---------+----------------------+\n",
       "| case_id | addres_district_368M |\n",
       "|   i64   |          str         |\n",
       "+================================+\n",
       "|  251566 |       a55475b1       |\n",
       "| 1930547 |       a55475b1       |\n",
       "| 2586625 |       a55475b1       |\n",
       "| 1881392 |       a55475b1       |\n",
       "| 2615871 |       a55475b1       |\n",
       "| 2657955 |       a55475b1       |\n",
       "| 1774201 |       a55475b1       |\n",
       "| 2670498 |       a55475b1       |\n",
       "| 1389479 |       a55475b1       |\n",
       "| 1466412 |       a55475b1       |\n",
       "| 1678359 |       a55475b1       |\n",
       "| 1850473 |       a55475b1       |\n",
       "| 2659890 |       a55475b1       |\n",
       "| 1274931 |       a55475b1       |\n",
       "| 1751755 |       a55475b1       |\n",
       "| 2672076 |       a55475b1       |\n",
       "|  208196 |       a55475b1       |\n",
       "| 1744181 |       a55475b1       |\n",
       "| 1353677 |       a55475b1       |\n",
       "|  905107 |       a55475b1       |\n",
       "| 1261411 |       a55475b1       |\n",
       "| 2530664 |       a55475b1       |\n",
       "| 1334798 |       a55475b1       |\n",
       "|  985068 |       a55475b1       |\n",
       "| 1613871 |       a55475b1       |\n",
       "|    …    |           …          |\n",
       "|  933668 |       a55475b1       |\n",
       "| 1640568 |       a55475b1       |\n",
       "| 1773081 |       a55475b1       |\n",
       "| 1845057 |       a55475b1       |\n",
       "|  820382 |       a55475b1       |\n",
       "|  35364  |       a55475b1       |\n",
       "|  879791 |       a55475b1       |\n",
       "| 1360977 |       a55475b1       |\n",
       "|  195950 |       a55475b1       |\n",
       "|  827724 |       a55475b1       |\n",
       "|  866557 |       a55475b1       |\n",
       "|   1131  |       a55475b1       |\n",
       "|  823428 |       a55475b1       |\n",
       "|  785691 |       a55475b1       |\n",
       "| 1490105 |       a55475b1       |\n",
       "| 1501347 |       a55475b1       |\n",
       "| 1517112 |       a55475b1       |\n",
       "| 1414220 |       a55475b1       |\n",
       "| 1723798 |       a55475b1       |\n",
       "| 1785035 |       a55475b1       |\n",
       "| 1692331 |       a55475b1       |\n",
       "| 1793282 |       a55475b1       |\n",
       "| 1361355 |       a55475b1       |\n",
       "|  598890 |       a55475b1       |\n",
       "|  879377 |       a55475b1       |\n",
       "+---------+----------------------+"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_person.group_by(\"case_id\").agg(pl.col(\"addres_district_368M\").max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "* [Home Credit Baseline](https://www.kaggle.com/code/greysky/home-credit-baseline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
